
####
## Output descriptions:

# Treasure Data (http://www.treasure-data.com/) provides cloud based data
# analytics platform, which easily stores and processes data from td-agent.
# FREE plan is also provided.
# @see http://docs.fluentd.org/articles/http-to-td
#
# This section matches events whose tag is td.DATABASE.TABLE
<match td.*.*>
  @type tdlog
  @id output_td
  apikey YOUR_API_KEY

  auto_create_table
  <buffer>
    @type file
    path /var/log/td-agent/buffer/td
  </buffer>

  <secondary>
    @type file
    path /var/log/td-agent/failed_records
  </secondary>
</match>


###################################################
# Customizing (Please read README.md in this directory)
###################################################

### Log Collect from Beats
<source>
  @type beats
  metadata_as_tag # (filebeat)
  # tag $${record['host']['hostname']}.yunan
  # port 5044 (default)
  # bind {ipaddr}
</source>

<filter *beat>
  @type parser
  key_name "message"
  #reserve_time true
  reserve_data true
  inject_key_prefix "msg."
  <parse>
    @type "json"
  </parse>
</filter>

### Forwarding all events from beats to each index on elasticsearch (default host: localhost)
<match *beat>
  @type elasticsearch_dynamic
  host ${elasticsearch-public-ip-here} # ElasticSearch IP
  #hosts x.x.x.x:9200,x.x.x.x:9200

  logstash_format true
  logstash_prefix td-agent-test
  #logstash_prefix monitor-$${record['host']['hostname']}-$${record['fields']['logtype']}
  #logstash_prefix monitor-$${tag_parts[0]}-$${record['log']['file']['path'][19..21]}

  <buffer>
    #@type file
    #path /var/log/td-agent/buffer/elastic.*.buffer
    @type memory
    flush_mode interval
    flush_interval 2s
    flush_thread_count 4
    queued_chunks_limit_size 4  # equals to flush_thread_count

    chunk_limit_size 2MB  # as small as possible
    total_limit_size 4GB

    retry_max_interval 30
    retry_timeout 72h # default
    </buffer>


</match>
